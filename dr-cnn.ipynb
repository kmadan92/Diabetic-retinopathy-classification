{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport glob\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nimport datetime\nimport matplotlib.pyplot as plt\nimport keras\nimport tensorflow as tf\nfrom skimage import io\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras import optimizers\nfrom keras.callbacks import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import activations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess = tf.compat.v1.Session\nprint(sess)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):\n a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n c = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint(sess.run)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.test.is_gpu_available())\nprint(tf.test.is_built_with_cuda())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.test.gpu_device_name()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.debugging.set_log_device_placement(True)\n\n# Place tensors on the CPU\nwith tf.device('/GPU:0'):\n  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n\n# Run on the GPU\nc = tf.matmul(a, b)\nprint(c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(keras.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining Path\ndata_path = '../input/diabeticretino-255/DR_Classify_256'\nclasses = ['0', '1','2', '3','4']\nnum_classes = len(classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = (256,256)\nchannels = 3\nbatch_size =16\ninput_size = (img_size[0], img_size[1], channels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, mode='train', ablation=None, flowers_cls=['0', '1','2', '3','4'], \n                 batch_size=32, dim=(256,256), n_channels=3, shuffle=True):\n        \"\"\"\n        Initialise the data generator\n        \"\"\"\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = {}\n        self.list_IDs = []\n        \n        # glob through directory of each class \n        for i, cls in enumerate(flowers_cls):\n            paths = glob.glob(os.path.join(data_path, cls, '*'))\n            brk_point = int(len(paths)*0.8)\n            if mode == 'train':\n                paths = paths[:brk_point]\n            else:\n                paths = paths[brk_point:]\n            if ablation is not None:\n                paths = paths[:ablation]\n            self.list_IDs += paths\n            self.labels.update({p:i for p in paths})\n            \n        self.n_channels = n_channels\n        self.n_classes = len(flowers_cls)\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n        \n        delete_rows = []\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            img = io.imread(ID)\n            img = img/255\n            #if img.shape[0] > 256 and img.shape[1] > 256:\n            img = cv2.resize(img, img_size)\n            #else:\n            #    delete_rows.append(i)\n            #    continue\n            X[i,] = img\n          \n            # Store class\n            y[i] = self.labels[ID]\n           \n        \n        #X = np.delete(X, delete_rows, axis=0)\n        #y = np.delete(y, delete_rows, axis=0)\n        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model architecture\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3,3), padding='same',input_shape=input_size))\nmodel.add(BatchNormalization())\nmodel.add(layers.Activation(activations.relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128, (3,3),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(layers.Activation(activations.relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(256, (3,3),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(layers.Activation(activations.relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(512, (3,3),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(layers.Activation(activations.relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(1024, (3,3),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(layers.Activation(activations.relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu'))\n\nmodel.add(Dense(num_classes, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compile model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet = tf.keras.applications.ResNet50(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=None,\n    pooling=None,\n    classes=5\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary\nresnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class roc_callback(Callback):\n    \n    def on_train_begin(self, logs={}):\n        logs['val_auc'] = 0\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_p = []\n        y_v = []\n        for i in range(len(validation_generator)):\n            x_val, y_val = validation_generator[i]\n            y_pred = self.model.predict(x_val)\n            y_p.append(y_pred)\n            y_v.append(y_val)\n        y_p = np.concatenate(y_p)\n        y_v = np.concatenate(y_v)\n        roc_auc = roc_auc_score(y_v, y_p)\n        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n        logs['val_auc'] = roc_auc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"curr_dt_time = datetime.datetime.now()\nmodel_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{accuracy:.5f}-{val_loss:.5f}-{val_accuracy:.5f}.h5'\n\n\n#EarlyStopping = EarlyStopping(monitor='val_loss', patience=21, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='categorical_accuracy', verbose=2, save_best_only=True, save_weights_only=False, mode='max', period=1)\n\nLR = ReduceLROnPlateau(monitor='categorical_accuracy', factor=0.2,patience=12, cooldown =5,verbose=2, min_lr=0.001)\n\nauc_logger = roc_callback()\n\ncallbacks_list = [LR, auc_logger]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(self, mode='train', ablation=None, flowers_cls=['0', '1','2', '3','4'], \n  #               batch_size=32, dim=(256,256), n_channels=3, shuffle=True):\ntraining_generator = DataGenerator('train', batch_size=128)\nvalidation_generator = DataGenerator('val', batch_size=128)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\nmodel.fit(training_generator,\n            batch_size=batch_size,\n            epochs=150,\n            callbacks=callbacks_list,\n            validation_data=validation_generator,\n            shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}